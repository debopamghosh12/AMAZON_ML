{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOlK3IfTyirGs7KTel5/ozX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M9IWpgkl6xQO","executionInfo":{"status":"ok","timestamp":1760348109944,"user_tz":-330,"elapsed":64438,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"9bbe6363-901d-477b-a9f0-8fe1f505cd21"},"outputs":[{"output_type":"stream","name":"stdout","text":["--> Mounting Google Drive...\n","Mounted at /content/drive\n","--> Google Drive mounted successfully!\n","\n","--> Loading 30 saved feature chunks from Google Drive...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:43<00:00,  1.44s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> All features loaded and combined successfully!\n","--> Final feature matrix shape: (75000, 22049)\n","--> Final labels array shape: (75000,)\n"]}],"source":["# Block 1: Mount Drive and Load All Processed Features\n","\n","from google.colab import drive\n","from scipy.sparse import vstack, load_npz, csr_matrix\n","import numpy as np\n","import glob\n","import os\n","from tqdm import tqdm\n","\n","# --- Mount Google Drive ---\n","print(\"--> Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"--> Google Drive mounted successfully!\")\n","\n","\n","# --- Load All Saved Feature Chunks from Google Drive ---\n","FEATURES_DIR = '/content/drive/MyDrive/ML_Competition/processed_features'\n","all_X = []\n","all_y = []\n","feature_files = sorted(glob.glob(os.path.join(FEATURES_DIR, \"*.npz\")))\n","\n","if not feature_files:\n","    print(\"CRITICAL ERROR: No feature files found. Check the FEATURES_DIR path.\")\n","else:\n","    print(f\"\\n--> Loading {len(feature_files)} saved feature chunks from Google Drive...\")\n","    for filename in tqdm(feature_files):\n","        with np.load(filename, allow_pickle=True) as loaded:\n","            X_chunk = csr_matrix((loaded['data'], loaded['indices'], loaded['indptr']), shape=loaded['shape'])\n","            all_X.append(X_chunk)\n","            all_y.append(loaded['labels'])\n","\n","    # --- Combine all chunks into one final dataset ---\n","    X_final_features = vstack(all_X)\n","    y_final = np.concatenate(all_y)\n","\n","    print(\"\\n--> All features loaded and combined successfully!\")\n","    print(f\"--> Final feature matrix shape: {X_final_features.shape}\")\n","    print(f\"--> Final labels array shape: {y_final.shape}\")"]},{"cell_type":"code","source":["# Block 2: Train Your Final Model with Early Stopping\n","\n","import lightgbm as lgb\n","from sklearn.model_selection import train_test_split\n","import joblib\n","\n","if 'X_final_features' not in locals():\n","    print(\"Please run Block 1 first to load the data.\")\n","else:\n","    # --- Create a single Train/Validation split ---\n","    # We'll use 80% for training, 20% for validation and early stopping\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_final_features, y_final, test_size=0.2, random_state=42\n","    )\n","\n","    # --- Define a strong set of parameters ---\n","    # These are good, robust parameters that don't need tuning in a time crunch.\n","    params = {\n","        'objective': 'regression_l1', # MAE is robust\n","        'metric': 'rmse',\n","        'n_estimators': 2000, # Train up to 2000 trees...\n","        'learning_rate': 0.02,\n","        'feature_fraction': 0.8,\n","        'bagging_fraction': 0.8,\n","        'bagging_freq': 1,\n","        'lambda_l1': 0.1,\n","        'lambda_l2': 0.1,\n","        'num_leaves': 40,\n","        'verbose': -1,\n","        'n_jobs': -1,\n","        'seed': 42,\n","        'boosting_type': 'gbdt',\n","    }\n","\n","    print(\"\\n--> Training a single, powerful model with early stopping...\")\n","    # ...but stop automatically if the score on the validation set doesn't improve for 100 rounds.\n","    model = lgb.LGBMRegressor(**params)\n","    model.fit(X_train, y_train,\n","              eval_set=[(X_val, y_val)],\n","              eval_metric='rmse',\n","              callbacks=[lgb.early_stopping(100, verbose=True)])\n","\n","    # --- Save your precious model immediately! ---\n","    MODEL_SAVE_PATH = '/content/drive/MyDrive/ML_Competition/final_model_emergency.joblib'\n","    joblib.dump(model, MODEL_SAVE_PATH)\n","\n","    print(\"\\n\\n*** YOUR COMPETITION MODEL IS TRAINED AND SAVED! ***\")\n","    print(f\"--> Final model saved to: {MODEL_SAVE_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ofCYQk007Iyw","executionInfo":{"status":"ok","timestamp":1760351466625,"user_tz":-330,"elapsed":3341824,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"dc76ac02-6643-4c0e-9104-6acc3cb3d1b9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--> Training a single, powerful model with early stopping...\n","Training until validation scores don't improve for 100 rounds\n","Did not meet early stopping. Best iteration is:\n","[2000]\tvalid_0's rmse: 0.67971\n","\n","\n","*** YOUR COMPETITION MODEL IS TRAINED AND SAVED! ***\n","--> Final model saved to: /content/drive/MyDrive/ML_Competition/final_model_emergency.joblib\n"]}]},{"cell_type":"code","source":["# Block 3 (Revised): The Final Submission Pipeline\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","import gc\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import torch\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from PIL import Image\n","from io import BytesIO\n","import requests\n","from tqdm import tqdm\n","import joblib\n","\n","# --- STEP 0: RE-DEFINE ALL NECESSARY FUNCTIONS AND OBJECTS ---\n","# This step is crucial because we are in a new notebook.\n","\n","print(\"--> Step 0: Defining all necessary functions and loading models...\")\n","\n","def extract_pack_quantity(text):\n","    if not isinstance(text, str): return 1.0\n","    match = re.search(r'Value:\\s*([\\d.]+)', text)\n","    return float(match.group(1)) if match else 1.0\n","\n","def get_image_features(image_path, model):\n","    try:\n","        img = Image.open(image_path).convert('RGB')\n","        img_t = preprocess(img)\n","        batch_t = torch.unsqueeze(img_t, 0)\n","        with torch.no_grad(): features = model(batch_t)\n","        return features.squeeze().numpy()\n","    except Exception as e:\n","        return np.zeros(2048)\n","\n","# --- Re-create and fit the Vectorizer ---\n","# We MUST use the same vocabulary, so we fit it on the first chunk of the TRAIN data again.\n","print(\"--> Fitting the TF-IDF vectorizer on a sample of the training data...\")\n","TRAIN_FILE = '/content/drive/MyDrive/ML DATASET/student_resource/dataset/train.csv'\n","vectorizer = TfidfVectorizer(max_features=20000, stop_words='english', ngram_range=(1, 2))\n","temp_df = pd.read_csv(TRAIN_FILE, nrows=2500) # Using the same chunk size\n","temp_df['catalog_content'] = temp_df['catalog_content'].fillna('')\n","vectorizer.fit(temp_df['catalog_content'])\n","del temp_df\n","print(\"--> Vectorizer is ready.\")\n","\n","\n","# --- Re-load the ResNet model ---\n","print(\"--> Loading the pre-trained ResNet-50 model...\")\n","model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","model = torch.nn.Sequential(*(list(model.children())[:-1]))\n","model.eval()\n","preprocess = transforms.Compose([\n","    transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","# --- STEP 1: LOAD YOUR TRAINED MODEL ---\n","print(\"\\n--> Step 1: Loading your saved final model from Google Drive...\")\n","MODEL_PATH = '/content/drive/MyDrive/ML_Competition/final_model_emergency.joblib'\n","final_model = joblib.load(MODEL_PATH)\n","print(\"--> Model loaded successfully!\")\n","\n","\n","# --- STEP 2: PROCESS THE TEST DATA ---\n","# !!! UPDATE THIS PATH IF YOUR TEST FILE IS IN A DIFFERENT LOCATION !!!\n","TEST_FILE = '/content/drive/MyDrive/ML DATASET/student_resource/dataset/test.csv'\n","TEST_IMAGE_DIR = '/content/drive/MyDrive/ML_Competition/full_test_images'\n","os.makedirs(TEST_IMAGE_DIR, exist_ok=True)\n","\n","df_test = pd.read_csv(TEST_FILE)\n","print(f\"\\n--> Step 2: Processing {len(df_test)} rows from the test set...\")\n","\n","# A) Text and Engineered Features\n","df_test['item_pack_quantity'] = df_test['catalog_content'].apply(extract_pack_quantity)\n","df_test['catalog_content'] = df_test['catalog_content'].fillna('')\n","test_text_features = vectorizer.transform(df_test['catalog_content'])\n","test_engineered_features = csr_matrix(df_test[['item_pack_quantity']].values)\n","\n","# B) Image Features\n","print(f\"--> Downloading/Verifying {len(df_test)} TEST images...\")\n","for _, row in tqdm(df_test.iterrows(), total=df_test.shape[0]):\n","    image_path = os.path.join(TEST_IMAGE_DIR, f\"{row['sample_id']}.jpg\")\n","    if not os.path.exists(image_path):\n","        try:\n","            response = requests.get(row['image_link'], timeout=20)\n","            if response.status_code == 200:\n","                Image.open(BytesIO(response.content)).convert('RGB').save(image_path)\n","        except Exception: pass\n","\n","print(f\"--> Extracting features from TEST images...\")\n","test_image_features_list = [get_image_features(os.path.join(TEST_IMAGE_DIR, f\"{sid}.jpg\"), model) for sid in tqdm(df_test['sample_id'])]\n","test_image_features = np.array(test_image_features_list)\n","\n","# C) Combine all test features\n","X_test_final = hstack([test_text_features, test_engineered_features, csr_matrix(test_image_features)])\n","print(f\"--> Test data processed. Final feature shape: {X_test_final.shape}\")\n","\n","\n","# --- STEP 3: MAKE FINAL PREDICTIONS ---\n","print(\"\\n--> Step 3: Making final predictions...\")\n","final_log_predictions = final_model.predict(X_test_final)\n","final_predictions = np.expm1(final_log_predictions)\n","final_predictions[final_predictions < 0] = 0.01 # Ensure all prices are positive\n","\n","\n","# --- STEP 4: CREATE AND SAVE THE SUBMISSION FILE ---\n","print(\"\\n--> Step 4: Creating the submission file...\")\n","submission_df = pd.DataFrame({'sample_id': df_test['sample_id'], 'price': final_predictions})\n","SUBMISSION_PATH = '/content/drive/MyDrive/ML_Competition/submission_final.csv'\n","submission_df.to_csv(SUBMISSION_PATH, index=False)\n","\n","\n","print(\"\\n\\n--- ALL DONE! YOUR SUBMISSION IS READY! ---\")\n","print(f\"Submission file saved to your Google Drive at: {SUBMISSION_PATH}\")\n","print(\"You can now download this file and submit it to the competition.\")\n","print(\"\\nSubmission Preview:\")\n","print(submission_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":616},"id":"Wp_34e-AIBde","executionInfo":{"status":"error","timestamp":1760364286236,"user_tz":-330,"elapsed":12341177,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"00368dfa-a694-4e1e-a346-7a32e16a9334"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--> Step 0: Defining all necessary functions and loading models...\n","--> Fitting the TF-IDF vectorizer on a sample of the training data...\n","--> Vectorizer is ready.\n","--> Loading the pre-trained ResNet-50 model...\n","Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97.8M/97.8M [00:01<00:00, 99.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> Step 1: Loading your saved final model from Google Drive...\n","--> Model loaded successfully!\n","\n","--> Step 2: Processing 75000 rows from the test set...\n","--> Downloading/Verifying 75000 TEST images...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 75000/75000 [3:07:36<00:00,  6.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["--> Extracting features from TEST images...\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 2262/75000 [17:13<9:13:48,  2.19it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3998229964.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--> Extracting features from TEST images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mtest_image_features_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_IMAGE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{sid}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0mtest_image_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image_features_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3998229964.py\u001b[0m in \u001b[0;36mget_image_features\u001b[0;34m(image_path, model)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimg_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbatch_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Block 1 (Emergency): Load Features and Train a TEXT-ONLY Model\n","\n","from google.colab import drive\n","from scipy.sparse import vstack, load_npz, csr_matrix\n","import numpy as np\n","import glob\n","import os\n","from tqdm import tqdm\n","import lightgbm as lgb\n","import joblib\n","\n","# --- Mount Google Drive ---\n","print(\"--> Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","\n","# --- Load Feature Chunks and Keep ONLY Text Features ---\n","FEATURES_DIR = '/content/drive/MyDrive/ML_Competition/processed_features'\n","all_X_text_only = []\n","all_y = []\n","feature_files = sorted(glob.glob(os.path.join(FEATURES_DIR, \"*.npz\")))\n","\n","print(f\"\\n--> Loading {len(feature_files)} chunks and extracting TEXT features only...\")\n","for filename in tqdm(feature_files):\n","    with np.load(filename, allow_pickle=True) as loaded:\n","        X_chunk = csr_matrix((loaded['data'], loaded['indices'], loaded['indptr']), shape=loaded['shape'])\n","        # THIS IS THE KEY: We slice the matrix to remove the last 2048 image feature columns\n","        num_text_features = X_chunk.shape[1] - 2048\n","        all_X_text_only.append(X_chunk[:, :num_text_features])\n","        all_y.append(loaded['labels'])\n","\n","# --- Combine all text-only chunks ---\n","X_text_final = vstack(all_X_text_only)\n","y_text_final = np.concatenate(all_y)\n","print(\"\\n--> All TEXT features loaded and combined successfully!\")\n","print(f\"--> Final text-only feature matrix shape: {X_text_final.shape}\")\n","\n","# --- Train a fast, new model on this data ---\n","params = {\n","    'objective': 'regression_l1', 'metric': 'rmse', 'n_estimators': 2000,\n","    'learning_rate': 0.02, 'feature_fraction': 0.8, 'bagging_fraction': 0.8,\n","    'bagging_freq': 1, 'lambda_l1': 0.1, 'lambda_l2': 0.1, 'num_leaves': 40,\n","    'verbose': -1, 'n_jobs': -1, 'seed': 42, 'boosting_type': 'gbdt',\n","}\n","\n","print(\"\\n--> Training a new TEXT-ONLY model...\")\n","text_only_model = lgb.LGBMRegressor(**params)\n","# No need for early stopping here, we'll train on the full data directly for max power.\n","text_only_model.fit(X_text_final, y_text_final)\n","\n","# --- Save this new model ---\n","MODEL_SAVE_PATH = '/content/drive/MyDrive/ML_Competition/text_only_model_final.joblib'\n","joblib.dump(text_only_model, MODEL_SAVE_PATH)\n","\n","print(\"\\n\\n*** TEXT-ONLY MODEL IS TRAINED AND SAVED! ***\")\n","print(f\"--> Model saved to: {MODEL_SAVE_PATH}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcPZNB9B42O8","executionInfo":{"status":"ok","timestamp":1760366487096,"user_tz":-330,"elapsed":2182011,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"8c5cdf0c-feb6-480c-db54-7a734975345e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--> Mounting Google Drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","--> Loading 30 chunks and extracting TEXT features only...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:47<00:00,  1.57s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> All TEXT features loaded and combined successfully!\n","--> Final text-only feature matrix shape: (75000, 20001)\n","\n","--> Training a new TEXT-ONLY model...\n","\n","\n","*** TEXT-ONLY MODEL IS TRAINED AND SAVED! ***\n","--> Model saved to: /content/drive/MyDrive/ML_Competition/text_only_model_final.joblib\n"]}]},{"cell_type":"code","source":["# Block 2 (Emergency): Generate TEXT-ONLY Submission\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","from scipy.sparse import hstack, csr_matrix\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from tqdm import tqdm\n","import joblib\n","\n","# --- Redefine functions and objects needed for text processing ---\n","def extract_pack_quantity(text):\n","    if not isinstance(text, str): return 1.0\n","    match = re.search(r'Value:\\s*([\\d.]+)', text)\n","    return float(match.group(1)) if match else 1.0\n","\n","TRAIN_FILE = '/content/drive/MyDrive/ML DATASET/student_resource/dataset/train.csv'\n","vectorizer = TfidfVectorizer(max_features=20000, stop_words='english', ngram_range=(1, 2))\n","temp_df = pd.read_csv(TRAIN_FILE, nrows=2500)\n","temp_df['catalog_content'] = temp_df['catalog_content'].fillna('')\n","vectorizer.fit(temp_df['catalog_content'])\n","del temp_df\n","\n","# --- Load your TEXT-ONLY trained model ---\n","print(\"--> Loading your saved text-only model...\")\n","MODEL_PATH = '/content/drive/MyDrive/ML_Competition/text_only_model_final.joblib'\n","text_only_model = joblib.load(MODEL_PATH)\n","\n","# --- Process Test Data (TEXT ONLY) ---\n","TEST_FILE = '/content/drive/MyDrive/ML DATASET/student_resource/dataset/test.csv'\n","df_test = pd.read_csv(TEST_FILE)\n","print(f\"\\n--> Applying TEXT-ONLY feature engineering to {len(df_test)} test samples...\")\n","df_test['item_pack_quantity'] = df_test['catalog_content'].apply(extract_pack_quantity)\n","df_test['catalog_content'] = df_test['catalog_content'].fillna('')\n","test_text_features = vectorizer.transform(df_test['catalog_content'])\n","test_engineered_features = csr_matrix(df_test[['item_pack_quantity']].values)\n","\n","X_test_text_final = hstack([test_text_features, test_engineered_features])\n","\n","# --- Make Final Predictions ---\n","print(\"\\n--> Making final predictions with text-only model...\")\n","final_log_predictions = text_only_model.predict(X_test_text_final)\n","final_predictions = np.expm1(final_log_predictions)\n","final_predictions[final_predictions < 0] = 0.01\n","\n","# --- Create and Save the Submission File ---\n","submission_df = pd.DataFrame({'sample_id': df_test['sample_id'], 'price': final_predictions})\n","SUBMISSION_PATH = '/content/drive/MyDrive/ML_Competition/submission_EMERGENCY_TEXT_ONLY.csv'\n","submission_df.to_csv(SUBMISSION_PATH, index=False)\n","\n","print(\"\\n\\n--- SUBMISSION READY! ---\")\n","print(f\"Submission file saved to: {SUBMISSION_PATH}\")\n","print(\"Download this from your Drive and submit it NOW.\")\n","print(\"\\nSubmission Preview:\")\n","print(submission_df.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G5pTKzOGB-gO","executionInfo":{"status":"ok","timestamp":1760366750887,"user_tz":-330,"elapsed":63333,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"539afd47-8d2b-4851-efcf-76bf993991f0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--> Loading your saved text-only model...\n","\n","--> Applying TEXT-ONLY feature engineering to 75000 test samples...\n","\n","--> Making final predictions with text-only model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","--- SUBMISSION READY! ---\n","Submission file saved to: /content/drive/MyDrive/ML_Competition/submission_EMERGENCY_TEXT_ONLY.csv\n","Download this from your Drive and submit it NOW.\n","\n","Submission Preview:\n","   sample_id      price\n","0     100179  13.698351\n","1     245611  15.389302\n","2     146263  17.813196\n","3      95658  10.845611\n","4      36806  27.073519\n"]}]}]}