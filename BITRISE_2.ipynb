{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxjrJ/FpBz1be7mTjrgEgs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiDb3gJc2SGf","executionInfo":{"status":"ok","timestamp":1760330194383,"user_tz":-330,"elapsed":67619,"user":{"displayName":"Debopam Ghosh","userId":"14948059590728999735"}},"outputId":"e1a85cac-8591-41db-afdc-6057ada3b8b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["--> Mounting Google Drive...\n","Mounted at /content/drive\n","--> Google Drive mounted successfully!\n","\n","--> Loading 30 saved feature chunks from Google Drive...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:43<00:00,  1.45s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","--> All features loaded and combined successfully!\n","--> Final feature matrix shape: (75000, 22049)\n","--> Final labels array shape: (75000,)\n"]}],"source":["# Block 1: Setup and Load All Processed Features\n","\n","from google.colab import drive\n","from scipy.sparse import vstack, load_npz, csr_matrix\n","import numpy as np\n","import glob\n","import os\n","from tqdm import tqdm\n","\n","# --- Mount Google Drive ---\n","print(\"--> Mounting Google Drive...\")\n","drive.mount('/content/drive')\n","print(\"--> Google Drive mounted successfully!\")\n","\n","\n","# --- Load All Saved Feature Chunks from Google Drive ---\n","\n","# This path MUST match where you saved your features\n","FEATURES_DIR = '/content/drive/MyDrive/ML_Competition/processed_features'\n","\n","all_X = []\n","all_y = []\n","# Find all the .npz files in your features directory\n","feature_files = sorted(glob.glob(os.path.join(FEATURES_DIR, \"*.npz\")))\n","\n","if not feature_files:\n","    print(\"CRITICAL ERROR: No feature files found in the 'processed_features' directory.\")\n","    print(\"Please make sure the path is correct and the previous step completed successfully.\")\n","else:\n","    print(f\"\\n--> Loading {len(feature_files)} saved feature chunks from Google Drive...\")\n","\n","    for filename in tqdm(feature_files):\n","        with np.load(filename, allow_pickle=True) as loaded:\n","            # Reconstruct the sparse matrix for this chunk\n","            X_chunk = csr_matrix((loaded['data'], loaded['indices'], loaded['indptr']), shape=loaded['shape'])\n","            all_X.append(X_chunk)\n","            all_y.append(loaded['labels'])\n","\n","    # --- Combine all chunks into one final dataset ---\n","    X_final_features = vstack(all_X)\n","    y_final = np.concatenate(all_y)\n","\n","    print(\"\\n--> All features loaded and combined successfully!\")\n","    print(f\"--> Final feature matrix shape: {X_final_features.shape}\")\n","    print(f\"--> Final labels array shape: {y_final.shape}\")"]},{"cell_type":"code","source":["# Block 2: Tune and Train the Definitive Model\n","\n","import lightgbm as lgb\n","from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint, uniform\n","\n","if 'X_final_features' not in locals():\n","    print(\"Please run Block 1 first to load the data.\")\n","else:\n","    # --- Tune Hyperparameters on the Full Dataset ---\n","    print(\"\\n--> Starting hyperparameter tuning on the full dataset...\")\n","    print(\"(This is the final long step, it may take several hours)\")\n","\n","    param_dist = {\n","        'n_estimators': randint(200, 1500),\n","        'learning_rate': uniform(0.01, 0.05),\n","        'num_leaves': randint(31, 100),\n","        'max_depth': [-1, 20, 30],\n","        'reg_alpha': uniform(0, 0.5), # L1 regularization\n","        'reg_lambda': uniform(0, 0.5), # L2 regularization\n","    }\n","\n","    lgbm = lgb.LGBMRegressor(random_state=42, n_jobs=-1)\n","\n","    # We'll run 15-20 iterations of search. More is better but takes longer.\n","    random_search = RandomizedSearchCV(\n","        lgbm, param_distributions=param_dist, n_iter=20,\n","        cv=3, scoring='neg_root_mean_squared_error', random_state=42, verbose=2\n","    )\n","\n","    random_search.fit(X_final_features, y_final)\n","\n","    print(\"\\n--> Tuning complete.\")\n","    print(f\"--> Best parameters found: {random_search.best_params_}\")\n","\n","    # --- Train the definitive model using the best found parameters ---\n","    print(\"\\n--> Training the final model on the entire dataset with the best parameters...\")\n","    final_model = lgb.LGBMRegressor(**random_search.best_params_, random_state=42, n_jobs=-1)\n","    final_model.fit(X_final_features, y_final)\n","\n","    print(\"\\n\\n*** YOUR COMPETITION MODEL IS TRAINED AND READY! ***\")\n","    print(\"The variable 'final_model' now holds your fully trained and optimized model.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJA0tic620kY","outputId":"2fbac0b6-fd48-4cd4-dd66-1c0ab47cbb47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--> Starting hyperparameter tuning on the full dataset...\n","(This is the final long step, it may take several hours)\n","Fitting 3 folds for each of 20 candidates, totalling 60 fits\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.118772 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.028727005942368128, max_depth=-1, n_estimators=1494, num_leaves=91, reg_alpha=0.2984250789732435, reg_lambda=0.22291637642679557; total time=66.2min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.091373 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.028727005942368128, max_depth=-1, n_estimators=1494, num_leaves=91, reg_alpha=0.2984250789732435, reg_lambda=0.22291637642679557; total time=67.4min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.187392 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.028727005942368128, max_depth=-1, n_estimators=1494, num_leaves=91, reg_alpha=0.2984250789732435, reg_lambda=0.22291637642679557; total time=60.6min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.541787 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.014998745790900145, max_depth=30, n_estimators=287, num_leaves=54, reg_alpha=0.32544423647442644, reg_lambda=0.028205789513550128; total time=12.7min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.452143 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.014998745790900145, max_depth=30, n_estimators=287, num_leaves=54, reg_alpha=0.32544423647442644, reg_lambda=0.028205789513550128; total time=13.0min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.733055 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.014998745790900145, max_depth=30, n_estimators=287, num_leaves=54, reg_alpha=0.32544423647442644, reg_lambda=0.028205789513550128; total time=11.9min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.049651 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.04609993861334124, max_depth=20, n_estimators=1005, num_leaves=32, reg_alpha=0.09091248360355031, reg_lambda=0.09170225492671691; total time=21.6min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 21.190533 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.04609993861334124, max_depth=20, n_estimators=1005, num_leaves=32, reg_alpha=0.09091248360355031, reg_lambda=0.09170225492671691; total time=21.9min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.904954 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.04609993861334124, max_depth=20, n_estimators=1005, num_leaves=32, reg_alpha=0.09091248360355031, reg_lambda=0.09170225492671691; total time=19.8min\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored on calling ctypes callback function: <function _log_callback at 0x7886687319e0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/lightgbm/basic.py\", line 287, in _log_callback\n","    def _log_callback(msg: bytes) -> None:\n","    \n","KeyboardInterrupt: \n"]},{"output_type":"stream","name":"stdout","text":["Auto-choosing col-wise multi-threading, the overhead of testing was 22.284802 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.02521211214797689, max_depth=20, n_estimators=452, num_leaves=79, reg_alpha=0.2623873301291946, reg_lambda=0.19993048585762774; total time=20.5min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.632008 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.02521211214797689, max_depth=20, n_estimators=452, num_leaves=79, reg_alpha=0.2623873301291946, reg_lambda=0.19993048585762774; total time=20.4min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.664217 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.02521211214797689, max_depth=20, n_estimators=452, num_leaves=79, reg_alpha=0.2623873301291946, reg_lambda=0.19993048585762774; total time=18.4min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.469565 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.012333283160680771, max_depth=30, n_estimators=389, num_leaves=92, reg_alpha=0.3925879806965068, reg_lambda=0.09983689107917987; total time=23.8min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.934086 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.012333283160680771, max_depth=30, n_estimators=389, num_leaves=92, reg_alpha=0.3925879806965068, reg_lambda=0.09983689107917987; total time=24.2min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.830296 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.012333283160680771, max_depth=30, n_estimators=389, num_leaves=92, reg_alpha=0.3925879806965068, reg_lambda=0.09983689107917987; total time=21.9min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.487601 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.03571172192068058, max_depth=-1, n_estimators=1354, num_leaves=81, reg_alpha=0.34015376929388985, reg_lambda=0.2252496259847715; total time=59.0min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.442280 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.03571172192068058, max_depth=-1, n_estimators=1354, num_leaves=81, reg_alpha=0.34015376929388985, reg_lambda=0.2252496259847715; total time=56.3min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 19.284936 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1403444\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17380\n","[LightGBM] [Info] Start training from score 2.742872\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.03571172192068058, max_depth=-1, n_estimators=1354, num_leaves=81, reg_alpha=0.34015376929388985, reg_lambda=0.2252496259847715; total time=48.7min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 21.069480 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1395253\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17031\n","[LightGBM] [Info] Start training from score 2.735708\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.010663248057993327, max_depth=-1, n_estimators=515, num_leaves=44, reg_alpha=0.40419867405823057, reg_lambda=0.15230688458668534; total time=20.0min\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 20.226698 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 1401511\n","[LightGBM] [Info] Number of data points in the train set: 50000, number of used features: 17402\n","[LightGBM] [Info] Start training from score 2.739072\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["[CV] END learning_rate=0.010663248057993327, max_depth=-1, n_estimators=515, num_leaves=44, reg_alpha=0.40419867405823057, reg_lambda=0.15230688458668534; total time=19.8min\n"]}]}]}